srun: Job 6375470 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 6375470
 0: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 0: hostname: nid008256 rank: 0 size: 16
 5: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 5: hostname: nid008257 rank: 5 size: 16
 9: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 9: hostname: nid008388 rank: 9 size: 16
 2: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 2: hostname: nid008256 rank: 2 size: 16
12: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
12: hostname: nid008389 rank: 12 size: 16
14: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
14: hostname: nid008389 rank: 14 size: 16
10: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
10: hostname: nid008388 rank: 10 size: 16
 7: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 7: hostname: nid008257 rank: 7 size: 16
13: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
13: hostname: nid008389 rank: 13 size: 16
 6: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 6: hostname: nid008257 rank: 6 size: 16
15: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
15: hostname: nid008389 rank: 15 size: 16
 3: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 3: hostname: nid008256 rank: 3 size: 16
 1: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 1: hostname: nid008256 rank: 1 size: 16
 5: Loading coo...
 0: Loading coo...
 8: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 8: hostname: nid008388 rank: 8 size: 16
 4: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
 4: hostname: nid008257 rank: 4 size: 16
 9: Loading coo...
11: Namespace(dataset='Amazon_Large_8', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid008256', normalize=False, partitioning='ONE5D', replication=2, timers=True, partitions='/pscratch/sd/j/jinimukh/Amazon_Large_8/processed/partitions.txt')
11: hostname: nid008388 rank: 11 size: 16
10: Loading coo...
 2: Loading coo...
12: Loading coo...
 7: Loading coo...
 6: Loading coo...
14: Loading coo...
 4: Loading coo...
 3: Loading coo...
 8: Loading coo...
 1: Loading coo...
13: Loading coo...
11: Loading coo...
15: Loading coo...
12: Done loading coo
13: Done loading coo
14: Done loading coo
15: Done loading coo
 0: Done loading coo
 1: Done loading coo
 3: Done loading coo
 2: Done loading coo
 4: Done loading coo
 5: Done loading coo
 6: Done loading coo
 7: Done loading coo
 8: Done loading coo
 9: Done loading coo
10: Done loading coo
11: Done loading coo
 0: 1668191
 0: 1779392
 0: 1779437
 0: 1897799
 0: 1691337
 0: 1755982
 0: 1779889
 0: 1897612
 0: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 0: 0
 0: rank: 0 adj_matrix_loc.size: torch.Size([14249639, 1668191])
 0: rank: 0 inputs_loc.size: torch.Size([1668191, 300])
 0: why segfault?
 4: 1668191
 4: 1779392
 4: 1779437
 4: 1897799
 4: 1691337
 4: 1755982
 4: 1779889
 4: 1897612
 4: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 4: 2
 4: rank: 4 adj_matrix_loc.size: torch.Size([14249639, 1779437])
 4: rank: 4 inputs_loc.size: torch.Size([1779437, 300])
 4: why segfault?
 5: 1668191
 5: 1779392
 5: 1779437
 5: 1897799
 5: 1691337
 5: 1755982
 5: 1779889
 5: 1897612
 5: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 5: 2
 5: rank: 5 adj_matrix_loc.size: torch.Size([14249639, 1779437])
 5: rank: 5 inputs_loc.size: torch.Size([1779437, 300])
 5: why segfault?
 3: 1668191
 3: 1779392
 3: 1779437
 3: 1897799
 3: 1691337
 3: 1755982
 3: 1779889
 3: 1897612
 3: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 3: 1
 3: rank: 3 adj_matrix_loc.size: torch.Size([14249639, 1779392])
 3: rank: 3 inputs_loc.size: torch.Size([1779392, 300])
 3: why segfault?
14: 1668191
14: 1779392
14: 1779437
14: 1897799
14: 1691337
14: 1755982
14: 1779889
14: 1897612
14: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
14: 7
14: rank: 14 adj_matrix_loc.size: torch.Size([14249639, 1897612])
14: rank: 14 inputs_loc.size: torch.Size([1897612, 300])
14: why segfault?
 6: 1668191
 6: 1779392
 6: 1779437
 6: 1897799
 6: 1691337
 6: 1755982
 6: 1779889
 6: 1897612
 6: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 6: 3
 6: rank: 6 adj_matrix_loc.size: torch.Size([14249639, 1897799])
 6: rank: 6 inputs_loc.size: torch.Size([1897799, 300])
 6: why segfault?
12: 1668191
12: 1779392
12: 1779437
12: 1897799
12: 1691337
12: 1755982
12: 1779889
12: 1897612
12: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
12: 6
12: rank: 12 adj_matrix_loc.size: torch.Size([14249639, 1779889])
12: rank: 12 inputs_loc.size: torch.Size([1779889, 300])
15: 1668191
15: 1779392
15: 1779437
15: 1897799
15: 1691337
15: 1755982
15: 1779889
15: 1897612
15: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
15: 7
15: rank: 15 adj_matrix_loc.size: torch.Size([14249639, 1897612])
15: rank: 15 inputs_loc.size: torch.Size([1897612, 300])
12: why segfault?
 1: 1668191
 1: 1779392
 1: 1779437
 1: 1897799
 1: 1691337
 1: 1755982
 1: 1779889
 1: 1897612
 1: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 1: 0
 1: rank: 1 adj_matrix_loc.size: torch.Size([14249639, 1668191])
 1: rank: 1 inputs_loc.size: torch.Size([1668191, 300])
15: why segfault?
 1: why segfault?
 0: reached here
 4: reached here
 5: reached here
13: 1668191
13: 1779392
13: 1779437
13: 1897799
13: 1691337
13: 1755982
13: 1779889
13: 1897612
13: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
13: 6
13: rank: 13 adj_matrix_loc.size: torch.Size([14249639, 1779889])
13: rank: 13 inputs_loc.size: torch.Size([1779889, 300])
13: why segfault?
 2: 1668191
 2: 1779392
 2: 1779437
 2: 1897799
 2: 1691337
 2: 1755982
 2: 1779889
 2: 1897612
 2: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 2: 1
 2: rank: 2 adj_matrix_loc.size: torch.Size([14249639, 1779392])
 2: rank: 2 inputs_loc.size: torch.Size([1779392, 300])
 2: why segfault?
 3: reached here
14: reached here
12: reached here
 6: reached here
15: reached here
 1: reached here
 7: 1668191
 7: 1779392
 7: 1779437
 7: 1897799
 7: 1691337
 7: 1755982
 7: 1779889
 7: 1897612
 7: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 7: 3
 7: rank: 7 adj_matrix_loc.size: torch.Size([14249639, 1897799])
 7: rank: 7 inputs_loc.size: torch.Size([1897799, 300])
 7: why segfault?
13: reached here
 2: reached here
 7: reached here
11: 1668191
11: 1779392
11: 1779437
11: 1897799
11: 1691337
11: 1755982
11: 1779889
11: 1897612
11: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
11: 5
11: rank: 11 adj_matrix_loc.size: torch.Size([14249639, 1755982])
11: rank: 11 inputs_loc.size: torch.Size([1755982, 300])
11: why segfault?
 8: 1668191
 8: 1779392
 8: 1779437
 8: 1897799
 8: 1691337
 8: 1755982
 8: 1779889
 8: 1897612
 8: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 8: 4
 8: rank: 8 adj_matrix_loc.size: torch.Size([14249639, 1691337])
 8: rank: 8 inputs_loc.size: torch.Size([1691337, 300])
 8: why segfault?
10: 1668191
10: 1779392
10: 1779437
10: 1897799
10: 1691337
10: 1755982
10: 1779889
10: 1897612
10: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
10: 5
10: rank: 10 adj_matrix_loc.size: torch.Size([14249639, 1755982])
10: rank: 10 inputs_loc.size: torch.Size([1755982, 300])
10: why segfault?
11: reached here
 8: reached here
 9: 1668191
 9: 1779392
 9: 1779437
 9: 1897799
 9: 1691337
 9: 1755982
 9: 1779889
 9: 1897612
 9: [0, 1668191, 3447583, 5227020, 7124819, 8816156, 10572138, 12352027, 14249639]
 9: 4
 9: rank: 9 adj_matrix_loc.size: torch.Size([14249639, 1691337])
 9: rank: 9 inputs_loc.size: torch.Size([1691337, 300])
10: reached here
 9: why segfault?
 9: reached here
 5: create GCN model
 5: pre send indices
 5: rank: 5 i: 0
 5: rank: 5 i: 1
 5: rank: 5 i: 2
 5: rank: 5 i: 3
 5: rank: 5 i: 4
 5: rank: 5 i: 5
 5: rank: 5 i: 6
 5: rank: 5 i: 7
 5: all to all counts
 5: all to all indices
 5: all to all done
 5: Epoch: 0
 9: create GCN model
 9: pre send indices
 9: rank: 9 i: 0
 9: rank: 9 i: 1
 9: rank: 9 i: 2
 9: rank: 9 i: 3
 9: rank: 9 i: 4
 9: rank: 9 i: 5
 9: rank: 9 i: 6
 9: rank: 9 i: 7
 9: all to all counts
 9: all to all indices
 9: all to all done
 9: Epoch: 0
 8: create GCN model
 8: pre send indices
 8: rank: 8 i: 0
 8: rank: 8 i: 1
 8: rank: 8 i: 2
 8: rank: 8 i: 3
 8: rank: 8 i: 4
 8: rank: 8 i: 5
 8: rank: 8 i: 6
 8: rank: 8 i: 7
 8: all to all counts
 8: all to all indices
 8: all to all done
 8: Epoch: 0
10: create GCN model
10: pre send indices
10: rank: 10 i: 0
10: rank: 10 i: 1
10: rank: 10 i: 2
10: rank: 10 i: 3
10: rank: 10 i: 4
10: rank: 10 i: 5
10: rank: 10 i: 6
10: rank: 10 i: 7
10: all to all counts
10: all to all indices
10: all to all done
10: Epoch: 0
11: create GCN model
11: pre send indices
11: rank: 11 i: 0
11: rank: 11 i: 1
11: rank: 11 i: 2
11: rank: 11 i: 3
11: rank: 11 i: 4
11: rank: 11 i: 5
11: rank: 11 i: 6
11: rank: 11 i: 7
11: all to all counts
11: all to all indices
11: all to all done
11: Epoch: 0
 6: create GCN model
 6: pre send indices
 6: rank: 6 i: 0
 6: rank: 6 i: 1
 6: rank: 6 i: 2
 6: rank: 6 i: 3
 6: rank: 6 i: 4
 6: rank: 6 i: 5
 6: rank: 6 i: 6
 6: rank: 6 i: 7
 6: all to all counts
 6: all to all indices
 6: all to all done
 6: Epoch: 0
 0: create GCN model
 0: pre send indices
 0: rank: 0 i: 0
 0: rank: 0 i: 1
 0: rank: 0 i: 2
 0: rank: 0 i: 3
 0: rank: 0 i: 4
 0: rank: 0 i: 5
 0: rank: 0 i: 6
 0: rank: 0 i: 7
 0: all to all counts
 0: all to all indices
 0: all to all done
 0: Epoch: 0
 1: create GCN model
 1: pre send indices
 1: rank: 1 i: 0
 1: rank: 1 i: 1
 1: rank: 1 i: 2
 1: rank: 1 i: 3
 1: rank: 1 i: 4
 1: rank: 1 i: 5
 1: rank: 1 i: 6
 1: rank: 1 i: 7
 1: all to all counts
 1: all to all indices
 1: all to all done
 1: Epoch: 0
 4: create GCN model
 4: pre send indices
 4: rank: 4 i: 0
 4: rank: 4 i: 1
 4: rank: 4 i: 2
 4: rank: 4 i: 3
 4: rank: 4 i: 4
 4: rank: 4 i: 5
 4: rank: 4 i: 6
 4: rank: 4 i: 7
 4: all to all counts
 4: all to all indices
 4: all to all done
 4: Epoch: 0
 7: create GCN model
 7: pre send indices
 7: rank: 7 i: 0
 7: rank: 7 i: 1
 7: rank: 7 i: 2
 7: rank: 7 i: 3
 7: rank: 7 i: 4
 7: rank: 7 i: 5
 7: rank: 7 i: 6
 7: rank: 7 i: 7
 7: all to all counts
 7: all to all indices
 7: all to all done
 7: Epoch: 0
 2: create GCN model
 2: pre send indices
 2: rank: 2 i: 0
 2: rank: 2 i: 1
 2: rank: 2 i: 2
 2: rank: 2 i: 3
 2: rank: 2 i: 4
 2: rank: 2 i: 5
 2: rank: 2 i: 6
 2: rank: 2 i: 7
 2: all to all counts
 2: all to all indices
 2: all to all done
 2: Epoch: 0
 3: create GCN model
 3: pre send indices
 3: rank: 3 i: 0
 3: rank: 3 i: 1
 3: rank: 3 i: 2
 3: rank: 3 i: 3
 3: rank: 3 i: 4
 3: rank: 3 i: 5
 3: rank: 3 i: 6
 3: rank: 3 i: 7
 3: all to all counts
 3: all to all indices
 3: all to all done
 3: Epoch: 0
14: create GCN model
14: pre send indices
14: rank: 14 i: 0
14: rank: 14 i: 1
14: rank: 14 i: 2
14: rank: 14 i: 3
14: rank: 14 i: 4
14: rank: 14 i: 5
14: rank: 14 i: 6
14: rank: 14 i: 7
14: all to all counts
14: all to all indices
14: all to all done
14: Epoch: 0
15: create GCN model
15: pre send indices
15: rank: 15 i: 0
15: rank: 15 i: 1
15: rank: 15 i: 2
15: rank: 15 i: 3
15: rank: 15 i: 4
15: rank: 15 i: 5
15: rank: 15 i: 6
15: rank: 15 i: 7
15: all to all counts
15: all to all indices
15: all to all done
15: Epoch: 0
12: create GCN model
12: pre send indices
12: rank: 12 i: 0
12: rank: 12 i: 1
12: rank: 12 i: 2
12: rank: 12 i: 3
12: rank: 12 i: 4
12: rank: 12 i: 5
12: rank: 12 i: 6
12: rank: 12 i: 7
12: all to all counts
12: all to all indices
12: all to all done
12: Epoch: 0
13: create GCN model
13: pre send indices
13: rank: 13 i: 0
13: rank: 13 i: 1
13: rank: 13 i: 2
13: rank: 13 i: 3
13: rank: 13 i: 4
13: rank: 13 i: 5
13: rank: 13 i: 6
13: rank: 13 i: 7
13: all to all counts
13: all to all indices
13: all to all done
13: Epoch: 0
 0:  ** On entry to cusparseSpMM_bufferSize(): dimension mismatch, matA.cols (1779392) != matB.cols (1668191) with opA = NON_TRANSPOSE, opB = TRANSPOSE
 0: 
 0:  ** On entry to cusparseSpMM(): dimension mismatch, matA.cols (1779392) != matB.cols (1668191) with opA = NON_TRANSPOSE, opB = TRANSPOSE
 0: 
 0: CUSPARSE API failed at line 199 with error: invalid value (3)
 0: CUSPARSE API failed at line 215 with error: invalid value (3)
 9:  ** On entry to cusparseSpMM_bufferSize(): dimension mismatch, matA.cols (1755982) != matB.cols (1691337) with opA = NON_TRANSPOSE, opB = TRANSPOSE
 9: 
 9: CUSPARSE API failed at line 199 with error: invalid value (3)
 9:  ** On entry to cusparseSpMM(): dimension mismatch, matA.cols (1755982) != matB.cols (1691337) with opA = NON_TRANSPOSE, opB = TRANSPOSE
 9: 
 9: CUSPARSE API failed at line 215 with error: invalid value (3)
 0: slurmstepd: error: *** STEP 6375470.2 ON nid008256 CANCELLED AT 2023-03-24T00:22:51 DUE TO TIME LIMIT ***
