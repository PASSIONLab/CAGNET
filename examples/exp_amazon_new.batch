#!/bin/bash
#SBATCH -A m1982_g
#SBATCH -C gpu
#SBATCH --job-name="job-1d-exp-Amazon"
#SBATCH -q regular
#SBATCH -t 1:00:00
#SBATCH -n 64
#SBATCH --ntasks-per-node=4
#SBATCH --gpus-per-task=1
#SBATCH --gpu-bind=map_gpu:0,1,2,3

export MASTER_ADDR=$(scontrol show hostnames | head -n 1)
echo $MASTER_ADDR

export CFLAGS="-I$CUDA_HOME/include"
export PYTHONPATH="/global/u2/j/jinimukh/CAGNET/sparse-extension/build/lib/python3.8/site-packages/sparse_coo_tensor_cpp-0.0.0-py3.8-linux-x86_64.egg":$PYTHONPATH
export PYTHONPATH="/global/u2/j/jinimukh/CAGNET/sparse-extension/build/lib/python3.8/site-packages:$PYTHONPATH"
module load  pytorch/1.9.0


srun -l -n 4 --ntasks-per-node=4 --gpus-per-task=1 --gpu-bind=map_gpu:0,1,2,3 python3 gcn_1d.py --dataset Amazon --n-epochs 100 --n-hidden 16 --weight-decay 0 --timers --hostname=$MASTER_ADDR &> ../slurm_outputs/new/p4_epochs100_amazon_mid16_act.txt

srun -l -n 16 --ntasks-per-node=4 --gpus-per-task=1 --gpu-bind=map_gpu:0,1,2,3 python3 gcn_1d.py --dataset Amazon --n-epochs 100 --n-hidden 16 --weight-decay 0 --timers --hostname=$MASTER_ADDR &> ../slurm_outputs/new/p16_epochs100_amazon_mid16_act.txt

srun -l -n 32 --ntasks-per-node=4 --gpus-per-task=1 --gpu-bind=map_gpu:0,1,2,3 python3 gcn_1d.py --dataset Amazon --n-epochs 100 --n-hidden 16 --weight-decay 0 --timers --hostname=$MASTER_ADDR &> ../slurm_outputs/new/p32_epochs100_amazon_mid16_act.txt

srun -l -n 64 --ntasks-per-node=4 --gpus-per-task=1 --gpu-bind=map_gpu:0,1,2,3 python3 gcn_1d.py --dataset Amazon --n-epochs 100 --n-hidden 16 --weight-decay 0 --timers --hostname=$MASTER_ADDR &> ../slurm_outputs/new/p64_epochs100_amazon_mid16_act.txt
