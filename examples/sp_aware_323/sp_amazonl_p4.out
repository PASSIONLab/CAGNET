1: Namespace(dataset='Amazon_Large', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid001441', normalize=False, partitioning='ONED', timers=True, partitions='')
1: hostname: nid001441 rank: 1 size: 4
3: Namespace(dataset='Amazon_Large', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid001441', normalize=False, partitioning='ONED', timers=True, partitions='')
3: hostname: nid001441 rank: 3 size: 4
0: Namespace(dataset='Amazon_Large', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid001441', normalize=False, partitioning='ONED', timers=True, partitions='')
0: hostname: nid001441 rank: 0 size: 4
2: Namespace(dataset='Amazon_Large', dropout=0.5, gpu=4, lr=0.01, n_epochs=100, n_hidden=16, n_layers=1, weight_decay=0.0, aggregator_type='gcn', world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', hostname='nid001441', normalize=False, partitioning='ONED', timers=True, partitions='')
2: hostname: nid001441 rank: 2 size: 4
1: 1
1: Loading coo...
3: 3
3: Loading coo...
2: 2
2: Loading coo...
0: 0
0: Loading coo...
0: Done loading coo
1: Done loading coo
3: Done loading coo
2: Done loading coo
0: partitioning...
3: partitioning...
1: partitioning...
2: partitioning...
3: rank: 3 adj_matrix_loc.size: torch.Size([14249639, 3562409])
3: rank: 3 inputs.size: torch.Size([14249639, 300])
3: done partitioning
2: rank: 2 adj_matrix_loc.size: torch.Size([14249639, 3562410])
2: rank: 2 inputs.size: torch.Size([14249639, 300])
0: rank: 0 adj_matrix_loc.size: torch.Size([14249639, 3562410])
0: rank: 0 inputs.size: torch.Size([14249639, 300])
2: done partitioning
0: done partitioning
1: rank: 1 adj_matrix_loc.size: torch.Size([14249639, 3562410])
1: rank: 1 inputs.size: torch.Size([14249639, 300])
1: done partitioning
2: tensor(3562403, device='cuda:2')
2: torch.Size([3562410, 3562410])
2: tensor(3562409, device='cuda:2')
2: torch.Size([3562410, 3562410])
2: tensor(3562408, device='cuda:2')
2: torch.Size([3562410, 3562410])
2: tensor(3562408, device='cuda:2')
2: torch.Size([3562410, 3562409])
2: Epoch: 0
0: tensor(3562408, device='cuda:0')
0: torch.Size([3562410, 3562410])
0: tensor(3562409, device='cuda:0')
0: torch.Size([3562410, 3562410])
0: tensor(3562405, device='cuda:0')
0: torch.Size([3562410, 3562410])
0: tensor(3562408, device='cuda:0')
0: torch.Size([3562410, 3562409])
0: Epoch: 0
1: tensor(3562408, device='cuda:1')
1: torch.Size([3562410, 3562410])
1: tensor(3562408, device='cuda:1')
1: torch.Size([3562410, 3562410])
1: tensor(3562408, device='cuda:1')
1: torch.Size([3562410, 3562410])
1: tensor(3562408, device='cuda:1')
1: torch.Size([3562410, 3562409])
1: Epoch: 0
3: tensor(3562405, device='cuda:3')
3: torch.Size([3562409, 3562410])
3: tensor(3562409, device='cuda:3')
3: torch.Size([3562409, 3562410])
3: tensor(3562401, device='cuda:3')
3: torch.Size([3562409, 3562410])
3: tensor(3562408, device='cuda:3')
3: torch.Size([3562409, 3562409])
3: Epoch: 0
0: Epoch: 1
1: Epoch: 1
2: Epoch: 1
3: Epoch: 1
0: Traceback (most recent call last):
0:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 620, in <module>
1: Traceback (most recent call last):
1:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 620, in <module>
2: Traceback (most recent call last):
2:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 620, in <module>
3: Traceback (most recent call last):
3:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 620, in <module>
0:     main(args)
0:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 532, in main
2:     main(args)
2:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 532, in main
1:     main(args)
1:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 532, in main
3:     main(args)
3:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 532, in main
0:     logits = model(g_loc, features_loc, ampbyp, epoch)
0:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
1:     logits = model(g_loc, features_loc, ampbyp, epoch)
1:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
2:     logits = model(g_loc, features_loc, ampbyp, epoch)
2:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
3:     logits = model(g_loc, features_loc, ampbyp, epoch)
3:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
1:     return forward_call(*input, **kwargs)
1:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 51, in forward
2:     return forward_call(*input, **kwargs)
2:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 51, in forward
0:     return forward_call(*input, **kwargs)
0:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 51, in forward
3:     return forward_call(*input, **kwargs)
3:   File "/global/u2/j/jinimukh/CAGNET/examples/gcn_1d.py", line 51, in forward
1:     h = layer(self, graph, h, ampbyp)
2:     h = layer(self, graph, h, ampbyp)
2:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
1:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
0:     h = layer(self, graph, h, ampbyp)
0:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
3:     h = layer(self, graph, h, ampbyp)
3:   File "/global/common/software/nersc/pm-2021q4/sw/pytorch/1.11.0/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
2:     return forward_call(*input, **kwargs)
2:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 660, in forward
1:     return forward_call(*input, **kwargs)
1:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 660, in forward
0:     return forward_call(*input, **kwargs)
0:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 660, in forward
3:     return forward_call(*input, **kwargs)
3:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 660, in forward
2:     return GCNFuncONED.apply(gcn, graph, ampbyp, inputs, self.weight)
2:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 676, in forward
1:     return GCNFuncONED.apply(gcn, graph, ampbyp, inputs, self.weight)
0:     return GCNFuncONED.apply(gcn, graph, ampbyp, inputs, self.weight)
0:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 676, in forward
1:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 676, in forward
3:     return GCNFuncONED.apply(gcn, graph, ampbyp, inputs, self.weight)
3:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 676, in forward
2:     z = broad_func_oned(self, graph, ampbyp, inputs)
2:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 69, in broad_func_oned
1:     z = broad_func_oned(self, graph, ampbyp, inputs)
1:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 69, in broad_func_oned
0:     z = broad_func_oned(self, graph, ampbyp, inputs)
0:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 69, in broad_func_oned
3:     z = broad_func_oned(self, graph, ampbyp, inputs)
3:   File "/global/homes/j/jinimukh/CAGNET/cagnet/nn/conv/gcn_conv.py", line 69, in broad_func_oned
2:     spmm_gpu(ampbyp[i].indices()[0].int(), ampbyp[i].indices()[1].int(),
2: RuntimeError: CUDA out of memory. Tried to allocate 3.98 GiB (GPU 2; 39.45 GiB total capacity; 30.18 GiB already allocated; 2.82 GiB free; 33.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
1:     spmm_gpu(ampbyp[i].indices()[0].int(), ampbyp[i].indices()[1].int(),
1: RuntimeError: CUDA out of memory. Tried to allocate 3.98 GiB (GPU 1; 39.45 GiB total capacity; 30.19 GiB already allocated; 2.81 GiB free; 33.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
0:     spmm_gpu(ampbyp[i].indices()[0].int(), ampbyp[i].indices()[1].int(),
0: RuntimeError: CUDA out of memory. Tried to allocate 3.98 GiB (GPU 0; 39.45 GiB total capacity; 30.19 GiB already allocated; 2.83 GiB free; 33.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
3:     spmm_gpu(ampbyp[i].indices()[0].int(), ampbyp[i].indices()[1].int(),
3: RuntimeError: CUDA out of memory. Tried to allocate 3.98 GiB (GPU 3; 39.45 GiB total capacity; 30.19 GiB already allocated; 2.83 GiB free; 33.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: nid001441: task 1: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=6233792.0
0: slurmstepd: error: *** STEP 6233792.0 ON nid001441 CANCELLED AT 2023-03-20T01:13:47 ***
srun: error: nid001441: tasks 0,2-3: Exited with exit code 1
