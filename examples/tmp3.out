0: Namespace(aggregator_type='gcn', batch_size=256, dataset='reddit', dist_backend='nccl', dist_url='env://', dropout=0.5, gpu=-1, hostname='127.0.0.1', lr=0.01, n_bulkmb=512, n_darts=-1, n_epochs=1, n_hidden=16, n_layers=1, normalize=False, partitioning='ONE5D', rank=-1, replication=1, samp_num=256, weight_decay=0.0, world_size=-1)
0: hostname: nid002781
0: hostname: nid002781 rank: 0 size: 1
0: start partitioning
0: rank: 0 adj_matrix_loc.size: torch.Size([232965, 232965])
0: rank: 0 inputs_loc.size: torch.Size([232965, 602])
0: end partitioning
0: coalescing
0: normalizing
0: done normalizing
0: imid: 18166615 val: 8172334.500000 arr[imid]: 2564784128.000000
0: imid: 9083307 val: 8172334.500000 arr[imid]: 1288451712.000000
0: imid: 4541653 val: 8172334.500000 arr[imid]: 640568896.000000
0: imid: 2270826 val: 8172334.500000 arr[imid]: 317143936.000000
0: imid: 1135412 val: 8172334.500000 arr[imid]: 159784208.000000
0: imid: 567705 val: 8172334.500000 arr[imid]: 80147880.000000
0: imid: 283852 val: 8172334.500000 arr[imid]: 41578028.000000
0: imid: 141925 val: 8172334.500000 arr[imid]: 20473418.000000
0: imid: 70962 val: 8172334.500000 arr[imid]: 9832408.000000
0: imid: 35480 val: 8172334.500000 arr[imid]: 5203542.000000
0: imid: 53221 val: 8172334.500000 arr[imid]: 7887794.000000
0: imid: 62091 val: 8172334.500000 arr[imid]: 8652051.000000
0: imid: 57656 val: 8172334.500000 arr[imid]: 8335342.500000
0: imid: 55438 val: 8172334.500000 arr[imid]: 8064393.500000
0: imid: 56547 val: 8172334.500000 arr[imid]: 8117769.000000
0: imid: 57101 val: 8172334.500000 arr[imid]: 8215006.000000
0: imid: 56824 val: 8172334.500000 arr[imid]: 8170865.500000
0: imid: 56962 val: 8172334.500000 arr[imid]: 8189993.000000
0: imid: 56893 val: 8172334.500000 arr[imid]: 8172020.500000
0: imid: 56927 val: 8172334.500000 arr[imid]: 8188378.500000
0: imid: 56910 val: 8172334.500000 arr[imid]: 8172235.500000
0: imid: 56918 val: 8172334.500000 arr[imid]: 8188236.000000
0: imid: 56914 val: 8172334.500000 arr[imid]: 8172336.000000
0: imid: 56912 val: 8172334.500000 arr[imid]: 8172327.000000
0: imid: 56913 val: 8172334.500000 arr[imid]: 8172329.000000
0: imid: 18166615 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 27249923 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 31791577 val: 3401610.500000 arr[imid]: 9985493.000000
0: imid: 29520750 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 30656163 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 31223870 val: 3401610.500000 arr[imid]: 9985493.000000
0: imid: 30940016 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 31081943 val: 3401610.500000 arr[imid]: 0.000000
0: imid: 31152906 val: 3401610.500000 arr[imid]: 6810933.000000
0: imid: 31117424 val: 3401610.500000 arr[imid]: 2159459.750000
0: imid: 31135165 val: 3401610.500000 arr[imid]: 4937014.500000
0: imid: 31126294 val: 3401610.500000 arr[imid]: 3478861.000000
0: imid: 31121859 val: 3401610.500000 arr[imid]: 2739246.250000
0: imid: 31124076 val: 3401610.500000 arr[imid]: 3059827.500000
0: imid: 31125185 val: 3401610.500000 arr[imid]: 3233514.500000
0: imid: 31125739 val: 3401610.500000 arr[imid]: 3426718.250000
0: imid: 31125462 val: 3401610.500000 arr[imid]: 3257614.000000
0: imid: 31125600 val: 3401610.500000 arr[imid]: 3265417.500000
0: imid: 31125669 val: 3401610.500000 arr[imid]: 3318082.250000
0: imid: 31125704 val: 3401610.500000 arr[imid]: 3421715.250000
0: imid: 31125686 val: 3401610.500000 arr[imid]: 3421321.000000
0: imid: 31125677 val: 3401610.500000 arr[imid]: 3420803.250000
0: imid: 31125673 val: 3401610.500000 arr[imid]: 3420798.750000
0: imid: 31125671 val: 3401610.500000 arr[imid]: 3318083.750000
0: imid: 31125672 val: 3401610.500000 arr[imid]: 3318098.000000
0: n_darts: 125952
0: rank: 0 g_loc: tensor(indices=tensor([[     0,      0,      0,  ..., 232964, 232964, 232964],
0:                        [     0,    242,    249,  ..., 232594, 232634, 232964]]),
0:        values=tensor([2.0568e-07, 2.0568e-07, 2.0568e-07,  ...,
0:                       4.1311e-06, 4.1311e-06, 4.1311e-06]),
0:        device='cuda:0', size=(232965, 232965), nnz=114848857,
0:        layout=torch.sparse_coo)
0: rank: 0 batches_loc: tensor(indices=tensor([[     0,      0,      0,  ...,    511,    511,    511],
0:                        [195991, 117560, 100852,  ..., 210813,  53334, 131122]]),
0:        values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
0:        device='cuda:0', size=(512, 232965), nnz=131072, layout=torch.sparse_coo)
0: probability-spgemm: 343.3492736816406
0: before p._values(): tensor([1.2276e+00, 1.8491e-01, 1.8721e+01,  ..., 3.6240e-01, 7.9862e+00,
0:         2.4029e+02], device='cuda:0')
0: before p._values()[56912]: 13.246072769165039 p_den[row[56912]]: 6.2924485206604
0: compute-p: 61.61203384399414
0: p.nnz: 36333230
0: pre-loop: 1.4520319700241089
0: p._values()[56912]: 2.105074405670166 ps_p_values[56912]: 8172327.0
0: iter_count: 1 dart_values: tensor([0.3990, 0.5167, 0.0249,  ..., 0.3437, 0.9927, 0.5703], device='cuda:0')
0: iter_count: 1 dart_values_scaled: tensor([3.9905e+06, 5.1668e+06, 2.4930e+05,  ..., 5.1134e+09, 5.1199e+09,
0:         5.1157e+09], device='cuda:0')
0: iter_count: 1 dart_hits_count.nnzidxs: tensor([[       4],
0:         [       8],
0:         [      11],
0:         ...,
0:         [36332465],
0:         [36332476],
0:         [36332500]], device='cuda:0')
0: iter_count: 1 dart_hits_count.nnzidxs.size: torch.Size([3563590, 1])
0: iter_count: 1 dart_hits_count.sum: 64487424
0: iter_count: 1 dart_hits_map: tensor([   27406,    34971,     3442,  ..., 36296107, 36331806, 36309730],
0:        device='cuda:0', dtype=torch.int32)
0: iter_count: 1 dart_hits_count: tensor([[  1],
0:         [  1],
0:         [  1],
0:         ...,
0:         [  9],
0:         [  5],
0:         [351]], device='cuda:0', dtype=torch.int32)
0: iter_count: 1 ps_p_values: tensor([0.0000e+00, 1.9509e-01, 2.2447e-01,  ..., 5.1202e+09, 5.1202e+09,
0:         5.1202e+09], device='cuda:0')
0: sampled_count: tensor([11024,  9666, 12520, 10538, 12932, 11469, 11153, 10402, 12684,  9842,
0:         12438, 13403, 12459, 10115, 11264, 12120, 13021, 13453, 12467, 11809,
0:         11179, 12947, 11294, 10516, 10519, 11119, 10005, 10003,  9595, 11595,
0:         13284, 11668,  8780,  9898, 12276, 11645, 10163, 10876, 10062,  9497,
0:         10663, 11791, 11570, 12157, 13784,  9359, 11432,  9263, 10236, 10962,
0:          9661, 10819, 10947, 10826, 10793, 10124,  8664,  9424, 10931,  9277,
0:          8969, 10122,  9018,  9295, 10272,  9501,  9365, 10336, 10197, 10276,
0:          8096, 10126,  9304,  9791,  9513,  8806,  8005,  9382,  7457,  8782,
0:          9591, 11029,  9743, 11499,  8958,  8565, 10265, 11149, 10869, 12021,
0:          8819,  9657,  7648,  9854, 10864,  9005,  9849,  9635, 10688,  9500,
0:         10095,  8867, 10907, 11618,  7965,  7262,  9538,  8247,  8774,  7919,
0:          7761,  7956,  7381,  8235,  8723,  9805,  8850,  7419,  8473,  7790,
0:          8735,  9197,  7685,  7017,  8090,  8958,  8467,  9538,  6961,  6832,
0:          9487,  8197,  8245,  7300,  8969,  7602,  7694,  8738,  7283,  7328,
0:          6346,  8730,  8239,  7295,  7483,  8942,  8718,  7367,  7956,  7476,
0:          7024,  7648,  7110,  9080,  8088,  9321,  8696,  8877,  7566,  9046,
0:          8364,  5883,  7471,  8178,  8085,  7091,  8098,  7641,  6458,  7959,
0:          7628,  9135,  9614,  6488,  8197,  7765, 10026,  6966,  7791,  7227,
0:          8740,  7021,  8104,  7890,  7465,  6500,  8742,  6896,  8484,  8183,
0:          8265,  7066,  7550,  6762,  7301,  7924,  7399,  6960,  6635,  8193,
0:          6658,  8946,  9388,  7317,  6856,  5976,  8725,  6323,  8338, 10963,
0:          8423,  6646,  8273,  8477,  7008,  6093,  5807,  5955,  5382,  5805,
0:          7292,  5586,  4903,  5398,  6756,  5422,  5375,  6447,  7429,  8104,
0:          7143,  7807,  6924,  6717,  6088,  5282,  7397,  5732,  5386,  7286,
0:          6578,  6753,  5975,  5473,  5728,  5789,  7533,  6489,  4791,  6969,
0:          6134,  6345,  5086,  5451,  6676,  5303,  5671,  5492,  5682,  5190,
0:          5790,  6892,  4640,  5092,  6053,  4556,  4478,  5817,  6266,  5773,
0:          5562,  5093,  7647,  5904,  5386,  7278,  5140,  4420,  5586,  5943,
0:          5722,  5877,  5422,  5381,  5198,  4538,  5971,  5915,  4892,  5487,
0:          5812,  5632,  5510,  7292,  5447,  4926,  5661,  5477,  6372,  5075,
0:          4935,  4570,  4551,  7161,  7198,  4613,  6546,  5083,  5790,  6444,
0:          6488,  5273,  5317,  6100,  6289,  5295,  5661,  5739,  4919,  6473,
0:          7321,  4467,  5162,  5626,  5163,  5242,  5738,  5566,  5668,  5366,
0:          5975,  6558,  4660,  5576,  4756,  5136,  5945,  5684,  5255,  5117,
0:          6296,  6262,  5105,  7194,  6323,  5272,  5927,  5982,  6396,  6069,
0:          6153,  7047,  6407,  5465,  6407,  5350,  5802,  5449,  5421,  6051,
0:          6494,  6544,  5567,  6552,  5296,  6268,  6327,  5792,  5634,  6637,
0:          5647,  5874,  5290,  4723,  4762,  5722,  5901,  5591,  5204,  6419,
0:          6053,  5675,  4983,  7242,  6072,  5344,  5710,  5781,  6664,  6667,
0:          5141,  5986,  4950,  4950,  4962,  6081,  6078,  4958,  5320,  5592,
0:          6145,  4617,  5423,  6351,  4915,  5882,  5784,  6182,  5397,  4903,
0:          5299,  6336,  5898,  6069,  4632,  5133,  6352,  5503,  5518,  5475,
0:          5775,  5268,  6240,  5027,  5523,  5914,  6114,  6852,  6178,  4491,
0:          4671,  4882,  4856,  4035,  4366,  4375,  4475,  4337,  4132,  4379,
0:          3563,  3770,  4201,  5074,  4138,  4800,  4169,  4887,  5110,  4784,
0:          3523,  4548,  4785,  3886,  4104,  4618,  4601,  4350,  4021,  3934,
0:          3695,  3647,  4122,  3875,  4670,  3810,  4459,  3030,  4273,  3011,
0:          4436,  4376,  4015,  4285,  4554,  4830,  4837,  5278,  4474,  4237,
0:          4983,  4089,  4022,  4586,  4258,  3467,  3603,  3786,  4418,  3655,
0:          3587,  3477,  3542,  5781,  3738,  4358,  3541,  3870,  3507,  3611,
0:          3784,  3311,  4182,  4893,  4322,  3625,  3868,  4655,  4744,  3510,
0:          4002,  3945], device='cuda:0', dtype=torch.int32)
0: p._values()[56912]: 0.0 ps_p_values[56912]: 0.0
0: iter_count: 2 dart_values: tensor([0.4230, 0.5678, 0.2647,  ..., 0.0191, 0.5965, 0.7411], device='cuda:0')
0: iter_count: 2 dart_values_scaled: tensor([4.2305e+06, 5.6784e+06, 2.6466e+06,  ..., 5.1102e+09, 5.1160e+09,
0:         5.1174e+09], device='cuda:0')
0: iter_count: 2 dart_hits_count.nnzidxs: tensor([[       0],
0:         [31104767],
0:         [31104773],
0:         ...,
0:         [31172045],
0:         [31172053],
0:         [31172057]], device='cuda:0')
0: iter_count: 2 dart_hits_count.nnzidxs.size: torch.Size([11976, 1])
0: iter_count: 2 dart_hits_count.sum: 64487424
0: iter_count: 2 dart_hits_map: tensor([31129386, 31143585, 31121122,  ...,        0,        0,        0],
0:        device='cuda:0', dtype=torch.int32)
0: iter_count: 2 dart_hits_count: tensor([[64361680],
0:         [       1],
0:         [       1],
0:         ...,
0:         [       1],
0:         [       1],
0:         [       1]], device='cuda:0', dtype=torch.int32)
0: iter_count: 2 ps_p_values: tensor([      0.,       0.,       0.,  ..., 9985493., 9985493., 9985493.],
0:        device='cuda:0')
0: imid: 18166615 val: 8172334.500000 arr[imid]: 2564784896.000000
0: imid: 9083307 val: 8172334.500000 arr[imid]: 1288451840.000000
0: imid: 4541653 val: 8172334.500000 arr[imid]: 640569024.000000
0: imid: 2270826 val: 8172334.500000 arr[imid]: 317144224.000000
0: imid: 1135412 val: 8172334.500000 arr[imid]: 159784624.000000
0: imid: 567705 val: 8172334.500000 arr[imid]: 80148176.000000
0: imid: 283852 val: 8172334.500000 arr[imid]: 41578188.000000
0: imid: 141925 val: 8172334.500000 arr[imid]: 20473426.000000
0: imid: 70962 val: 8172334.500000 arr[imid]: 9832383.000000
0: imid: 35480 val: 8172334.500000 arr[imid]: 5203529.000000
0: imid: 53221 val: 8172334.500000 arr[imid]: 7887774.500000
0: imid: 62091 val: 8172334.500000 arr[imid]: 8652029.000000
0: imid: 57656 val: 8172334.500000 arr[imid]: 8335322.500000
0: imid: 55438 val: 8172334.500000 arr[imid]: 8064373.500000
0: imid: 56547 val: 8172334.500000 arr[imid]: 8117749.500000
0: imid: 57101 val: 8172334.500000 arr[imid]: 8214986.500000
0: imid: 56824 val: 8172334.500000 arr[imid]: 8170845.500000
0: imid: 56962 val: 8172334.500000 arr[imid]: 8189973.500000
0: imid: 56893 val: 8172334.500000 arr[imid]: 8172001.000000
0: imid: 56927 val: 8172334.500000 arr[imid]: 8188358.500000
0: imid: 56910 val: 8172334.500000 arr[imid]: 8172215.500000
0: imid: 56918 val: 8172334.500000 arr[imid]: 8188216.000000
0: imid: 56914 val: 8172334.500000 arr[imid]: 8172316.000000
0: imid: 56916 val: 8172334.500000 arr[imid]: 8172323.500000
0: imid: 56917 val: 8172334.500000 arr[imid]: 8188216.000000
0: sampled_count: tensor([  257,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256, 11990,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256,   256,   256,   256,   256,   256,   256,   256,   256,
0:           256,   256], device='cuda:0', dtype=torch.int32)
0: construct-nextf: 0.7972480058670044
0: total_time: 3895.928466796875
0: spgemm-matc-inst total_time: 0.05878400057554245 avg_time 0.05878400057554245
0: spgemm-bcast-nnz total_time: 122.26163482666016 avg_time 122.26163482666016
0: spgemm-inst-recv total_time: 3.5645439624786377 avg_time 3.5645439624786377
0: spgemm-bcast-data total_time: 0.09523200243711472 avg_time 0.09523200243711472
0: spgemm-preproc-local total_time: 0.3563520014286041 avg_time 0.3563520014286041
0: spgemm-local-spgemm total_time: 96.65433502197266 avg_time 96.65433502197266
0: spgemm-chunk-inst total_time: 1.1634880304336548 avg_time 1.1634880304336548
0: spgemm-chunk-coalesce total_time: 33.33251190185547 avg_time 33.33251190185547
0: spgemm-chunk-add total_time: 1.1100159883499146 avg_time 1.1100159883499146
0: spgemm-matc-coalesce total_time: 0.01228800043463707 avg_time 0.01228800043463707
0: spgemm-reduce-nnz total_time: 36.91321563720703 avg_time 36.91321563720703
0: spgemm-padding total_time: 1.8552320003509521 avg_time 1.8552320003509521
0: spgemm-allgather total_time: 2.268160104751587 avg_time 2.268160104751587
0: spgemm-preproc-reduce total_time: 1.1533440351486206 avg_time 1.1533440351486206
0: spgemm-reduce total_time: 39.05833435058594 avg_time 39.05833435058594
0: spgemm-unpad total_time: 3.018752098083496 avg_time 3.018752098083496
0: prob-rowsum total_time: 1.2051519751548767 avg_time 0.6025759875774384
0: gen-darts total_time: 0.44383999705314636 avg_time 0.22191999852657318
0: dart-throw total_time: 3.201184034347534 avg_time 1.600592017173767
0: filter_darts total_time: 73.3745288848877 avg_time 36.68726444244385
0: add-to-frontier total_time: 3.6911680698394775 avg_time 1.8455840349197388
0: count_samples total_time: 61.86393737792969 avg_time 30.931968688964844
0: select-preproc total_time: 0.2099199965596199 avg_time 0.10495999827980995
0: select-psoverflow total_time: 1.9985919930040836 avg_time 0.062455999781377614
0: select-reciprocal total_time: 41.37455999851227 avg_time 1.2929549999535084
0: select-instmtx total_time: 36.437375664711 avg_time 1.1386679895222187
0: select-invsum total_time: 1894.122688293457 avg_time 59.19133400917053
0: select-psinv total_time: 2.2108160331845284 avg_time 0.06908800103701651
0: select-computedarts total_time: 1.884160004556179 avg_time 0.058880000142380595
0: select-throwdarts total_time: 10.209279954433441 avg_time 0.31903999857604504
0: select-add-to-frontier total_time: 53.809184312820435 avg_time 1.6815370097756386
0: select-samplecount total_time: 991.8761978149414 avg_time 30.99613118171692
0: select-overflow total_time: 2.233344040811062 avg_time 0.06979200127534568
0: select-iter total_time: 3043.3382110595703 avg_time 95.10431909561157
0: dart-selection total_time: 3054.8369750976562 avg_time 1527.4184875488281
0: set-probs total_time: 3.370400071144104 avg_time 1.685200035572052
0: compute-bool total_time: 0.10444800183176994 avg_time 0.05222400091588497
0: sampling-iters total_time: 3206.3609619140625 avg_time 1603.1804809570312
0: select-mtxs total_time: 0.9584640264511108 avg_time 0.9584640264511108
0: row-select-spgemm total_time: 198.93040466308594 avg_time 198.93040466308594
0: row-select-expand total_time: 2.83516788482666 avg_time 2.83516788482666
0: col-select-spgemm total_time: 79.16544342041016 avg_time 79.16544342041016
0: set-sample total_time: 0.12639999389648438 avg_time 0.12639999389648438
0: iter_count: 2
0: selection_iter_count: 32
0: 
0: probability-spgemm: 184.3711700439453
0: before p._values(): tensor([1.2276e+00, 1.8491e-01, 1.8721e+01,  ..., 3.6240e-01, 7.9862e+00,
0:         2.4029e+02], device='cuda:0')
0: before p._values()[56912]: 13.246072769165039 p_den[row[56912]]: 6.292463779449463
0: compute-p: 61.37958526611328
0: p.nnz: 36333230
0: pre-loop: 1.4438400268554688
0: p._values()[56912]: 2.105069398880005 ps_p_values[56912]: 8172307.0
0: iter_count: 1 dart_values: tensor([0.3990, 0.5167, 0.0249,  ..., 0.3437, 0.9927, 0.5703], device='cuda:0')
0: iter_count: 1 dart_values_scaled: tensor([3.9905e+06, 5.1668e+06, 2.4930e+05,  ..., 5.1134e+09, 5.1199e+09,
0:         5.1157e+09], device='cuda:0')
0: iter_count: 1 dart_hits_count.nnzidxs: tensor([[       4],
0:         [       8],
0:         [      11],
0:         ...,
0:         [36332465],
0:         [36332476],
0:         [36332500]], device='cuda:0')
0: iter_count: 1 dart_hits_count.nnzidxs.size: torch.Size([3563119, 1])
0: iter_count: 1 dart_hits_count.sum: 64487424
0: iter_count: 1 dart_hits_map: tensor([   27406,    34971,     3442,  ..., 36296107, 36331806, 36309730],
0:        device='cuda:0', dtype=torch.int32)
0: iter_count: 1 dart_hits_count: tensor([[  1],
0:         [  1],
0:         [  1],
0:         ...,
0:         [  9],
0:         [  6],
0:         [304]], device='cuda:0', dtype=torch.int32)
0: iter_count: 1 ps_p_values: tensor([0.0000e+00, 1.9508e-01, 2.2447e-01,  ..., 5.1202e+09, 5.1202e+09,
0:         5.1202e+09], device='cuda:0')
0: sampled_count: tensor([11038,  9667, 12520, 10568, 12768, 11472, 11310, 10395, 12761,  9910,
0:         12425, 13432, 12406, 10202, 11313, 12125, 12968, 13405, 12561, 11745,
0:         11194, 13006, 11227, 10395, 10354, 11110, 10107,  9996,  9598, 11741,
0:         13247, 11627,  8896,  9732, 12241, 11660, 10146, 10866, 10056,  9441,
0:         10619, 11767, 11657, 12170, 13797,  9380, 11389,  9277, 10227, 10911,
0:          9713, 10813, 10883, 10788, 10774, 10147,  8637,  9432, 10923,  9243,
0:          8978, 10170,  9043,  9322, 10205,  9454,  9322, 10353, 10208, 10225,
0:          8144, 10149,  9296,  9792,  9529,  8775,  7987,  9299,  7470,  8734,
0:          9667, 11008,  9733, 11530,  8974,  8481, 10398, 11173, 10894, 12060,
0:          8833,  9604,  7662,  9844, 10962,  9020,  9854,  9650, 10728,  9430,
0:          9986,  8931, 10908, 11575,  7910,  7259,  9472,  8202,  8697,  7909,
0:          7729,  7958,  7362,  8178,  8726,  9826,  8873,  7428,  8491,  7797,
0:          8774,  9180,  7704,  7044,  8096,  8939,  8507,  9518,  6994,  6797,
0:          9494,  8138,  8264,  7249,  8939,  7621,  7669,  8734,  7287,  7316,
0:          6354,  8748,  8245,  7315,  7517,  8989,  8748,  7412,  7965,  7501,
0:          7025,  7581,  7108,  9104,  8063,  9321,  8660,  8851,  7581,  9014,
0:          8373,  5826,  7538,  8144,  8096,  7110,  8038,  7664,  6487,  7958,
0:          7668,  9196,  9613,  6476,  8282,  7659, 10054,  6929,  7765,  7205,
0:          8737,  7037,  8079,  7974,  7485,  6498,  8750,  6987,  8448,  8182,
0:          8264,  7058,  7538,  6759,  7273,  7974,  7404,  7022,  6559,  8117,
0:          6684,  8929,  9311,  7385,  6911,  5942,  8717,  6315,  8271, 10950,
0:          8465,  6670,  8323,  8505,  7032,  6099,  5850,  5951,  5400,  5759,
0:          7351,  5581,  4874,  5359,  6755,  5394,  5361,  6433,  7439,  8102,
0:          7114,  7830,  6920,  6708,  6093,  5274,  7424,  5738,  5379,  7267,
0:          6562,  6738,  5992,  5474,  5726,  5788,  7554,  6488,  4801,  6940,
0:          6136,  6347,  5074,  5442,  6645,  5304,  5738,  5504,  5699,  5204,
0:          5812,  6853,  4638,  5094,  6053,  4599,  4470,  5836,  6226,  5780,
0:          5567,  5083,  7659,  5864,  5411,  7339,  5100,  4415,  5586,  5915,
0:          5691,  5845,  5445,  5372,  5219,  4534,  5999,  5901,  4948,  5483,
0:          5827,  5630,  5559,  7246,  5467,  4884,  5687,  5437,  6376,  5074,
0:          4927,  4594,  4565,  7177,  7211,  4619,  6537,  5087,  5818,  6429,
0:          6468,  5271,  5313,  6125,  6296,  5253,  5661,  5748,  4891,  6444,
0:          7318,  4465,  5150,  5627,  5165,  5245,  5743,  5536,  5678,  5381,
0:          5976,  6579,  4661,  5609,  4757,  5146,  5963,  5703,  5237,  5114,
0:          6305,  6249,  5101,  7171,  6257,  5286,  5902,  6002,  6414,  6107,
0:          6152,  7072,  6410,  5420,  6363,  5397,  5770,  5405,  5389,  6049,
0:          6478,  6551,  5583,  6499,  5315,  6228,  6329,  5793,  5633,  6642,
0:          5634,  5870,  5306,  4701,  4764,  5709,  5925,  5587,  5220,  6395,
0:          6056,  5686,  4966,  7269,  6085,  5358,  5729,  5793,  6671,  6677,
0:          5130,  5999,  4952,  4937,  4914,  6034,  6079,  4927,  5301,  5592,
0:          6145,  4639,  5447,  6324,  4967,  5862,  5804,  6168,  5382,  4937,
0:          5316,  6335,  5866,  6072,  4615,  5088,  6393,  5489,  5479,  5455,
0:          5791,  5293,  6251,  5061,  5485,  5937,  6079,  6906,  6176,  4499,
0:          4670,  4883,  4850,  4041,  4373,  4377,  4486,  4337,  4142,  4381,
0:          3568,  3777,  4208,  5078,  4130,  4806,  4168,  4886,  5110,  4768,
0:          3521,  4537,  4789,  3878,  4083,  4622,  4588,  4356,  4019,  3927,
0:          3691,  3659,  4114,  3882,  4676,  3806,  4460,  3033,  4273,  3014,
0:          4441,  4391,  4001,  4294,  4560,  4828,  4845,  5278,  4482,  4241,
0:          4978,  4077,  4034,  4583,  4253,  3464,  3590,  3784,  4414,  3643,
0:          3593,  3463,  3547,  5781,  3719,  4350,  3535,  3868,  3506,  3610,
0:          3783,  3316,  4171,  4885,  4319,  3630,  3866,  4652,  4751,  3500,
0:          3998,  3950], device='cuda:0', dtype=torch.int32)
0: construct-nextf: 0.785535991191864
0: total_time: 1534.89404296875
0: spgemm-matc-inst total_time: 0.0414079986512661 avg_time 0.0414079986512661
0: spgemm-bcast-nnz total_time: 0.08691199868917465 avg_time 0.08691199868917465
0: spgemm-inst-recv total_time: 3.5993599891662598 avg_time 3.5993599891662598
0: spgemm-bcast-data total_time: 0.06860800087451935 avg_time 0.06860800087451935
0: spgemm-preproc-local total_time: 0.22015999257564545 avg_time 0.22015999257564545
0: spgemm-local-spgemm total_time: 96.85913848876953 avg_time 96.85913848876953
0: spgemm-chunk-inst total_time: 1.1541119813919067 avg_time 1.1541119813919067
0: spgemm-chunk-coalesce total_time: 33.36783981323242 avg_time 33.36783981323242
0: spgemm-chunk-add total_time: 1.1110399961471558 avg_time 1.1110399961471558
0: spgemm-matc-coalesce total_time: 0.01228800043463707 avg_time 0.01228800043463707
0: spgemm-reduce-nnz total_time: 0.08790399879217148 avg_time 0.08790399879217148
0: spgemm-padding total_time: 1.856160044670105 avg_time 1.856160044670105
0: spgemm-allgather total_time: 2.243583917617798 avg_time 2.243583917617798
0: spgemm-preproc-reduce total_time: 1.1478400230407715 avg_time 1.1478400230407715
0: spgemm-reduce total_time: 39.09904098510742 avg_time 39.09904098510742
0: spgemm-unpad total_time: 3.023871898651123 avg_time 3.023871898651123
0: prob-rowsum total_time: 0.5768319964408875 avg_time 0.5768319964408875
0: gen-darts total_time: 0.20255999267101288 avg_time 0.20255999267101288
0: dart-throw total_time: 1.5697599649429321 avg_time 1.5697599649429321
0: filter_darts total_time: 9.821632385253906 avg_time 9.821632385253906
0: add-to-frontier total_time: 1.8423360586166382 avg_time 1.8423360586166382
0: count_samples total_time: 30.70307159423828 avg_time 30.70307159423828
0: select-preproc total_time: 0.07065600156784058 avg_time 0.07065600156784058
0: select-psoverflow total_time: 0.6276479996740818 avg_time 0.06276479996740818
0: select-reciprocal total_time: 13.165791749954224 avg_time 1.3165791749954223
0: select-instmtx total_time: 11.41049611568451 avg_time 1.141049611568451
0: select-invsum total_time: 591.7541084289551 avg_time 59.17541084289551
0: select-psinv total_time: 0.6932480111718178 avg_time 0.06932480111718178
0: select-computedarts total_time: 0.6707199960947037 avg_time 0.06707199960947037
0: select-throwdarts total_time: 3.707904040813446 avg_time 0.3707904040813446
0: select-add-to-frontier total_time: 16.77183973789215 avg_time 1.6771839737892151
0: select-samplecount total_time: 310.00691413879395 avg_time 31.000691413879395
0: select-overflow total_time: 0.695296011865139 avg_time 0.0695296011865139
0: select-iter total_time: 951.7676544189453 avg_time 95.17676544189453
0: dart-selection total_time: 957.3478393554688 avg_time 957.3478393554688
0: set-probs total_time: 1.7666239738464355 avg_time 1.7666239738464355
0: compute-bool total_time: 0.04710400104522705 avg_time 0.04710400104522705
0: sampling-iters total_time: 1005.9694213867188 avg_time 1005.9694213867188
0: select-mtxs total_time: 0.9820160269737244 avg_time 0.9820160269737244
0: row-select-spgemm total_time: 197.51199340820312 avg_time 197.51199340820312
0: row-select-expand total_time: 2.815295934677124 avg_time 2.815295934677124
0: col-select-spgemm total_time: 79.22278594970703 avg_time 79.22278594970703
0: set-sample total_time: 0.12403199821710587 avg_time 0.12403199821710587
0: iter_count: 1
0: selection_iter_count: 10
0: 
0: return_dart_count1.nnzidxs: tensor([       4,        8,       11,  ..., 36332465, 36332476, 36332500],
0:        device='cuda:0')
0: return_dart_count1: tensor([  1,   1,   1,  ...,   9,   5, 351], device='cuda:0',
0:        dtype=torch.int32)
0: return_dart_map1: tensor([   27406,    34971,     3442,  ..., 36296107, 36331806, 36309730],
0:        device='cuda:0', dtype=torch.int32)
0: return_dart_val1: tensor([3.9905e+06, 5.1668e+06, 2.4930e+05,  ..., 5.1134e+09, 5.1199e+09,
0:         5.1157e+09], device='cuda:0')
0: return_dart_count2.nnzidxs: tensor([       4,        8,       11,  ..., 36332465, 36332476, 36332500],
0:        device='cuda:0')
0: return_dart_count2: tensor([  1,   1,   1,  ...,   9,   6, 304], device='cuda:0',
0:        dtype=torch.int32)
0: return_dart_map2: tensor([   27406,    34971,     3442,  ..., 36296107, 36331806, 36309730],
0:        device='cuda:0', dtype=torch.int32)
0: return_dart_val2: tensor([3.9905e+06, 5.1668e+06, 2.4930e+05,  ..., 5.1134e+09, 5.1199e+09,
0:         5.1157e+09], device='cuda:0')
0: 
0: unmatched_darts: tensor([      12,       43,       49,  ..., 64487415, 64487416, 64487417],
0:        device='cuda:0')
0: unmatched_darts.size: torch.Size([18767503])
0: dart_map1[unmatched]: tensor([   27788,    46136,    40383,  ..., 36273593, 36267529, 36273527],
0:        device='cuda:0', dtype=torch.int32)
0: dart_map2[unmatched]: tensor([   27789,    46138,    40388,  ..., 36273527, 36267509, 36273468],
0:        device='cuda:0', dtype=torch.int32)
0: 
0: dart_vals1[unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1114e+09, 5.1103e+09,
0:         5.1113e+09], device='cuda:0')
0: dart_vals2[unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1114e+09, 5.1103e+09,
0:         5.1113e+09], device='cuda:0')
0: 
0: ps_pvals1[map1unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1114e+09, 5.1103e+09,
0:         5.1113e+09], device='cuda:0')
0: ps_pvals2[map1unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1114e+09, 5.1103e+09,
0:         5.1114e+09], device='cuda:0')
0: 
0: ps_pvals1[map2unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1113e+09, 5.1103e+09,
0:         5.1113e+09], device='cuda:0')
0: ps_pvals2[map2unmatched]: tensor([4.0922e+06, 7.0450e+06, 5.6419e+06,  ..., 5.1114e+09, 5.1103e+09,
0:         5.1113e+09], device='cuda:0')
