0: Namespace(local_rank=None, accperrank=1, epochs=100, graphname='Cora', timing='False', midlayer=16, runcount=1, replication=1, normalization=None, activations='True', accuracy=None, download=None)
0: Arguments: epochs: 100 graph: Cora timing: False mid: 16 norm: False act: True acc: False runs: 1 rep: 1
0: nid001341
0: before process_group
0: after process_group
0: Processes: 1
0: rank: 0 adj_matrix_loc.size: torch.Size([2708, 2708])
0: rank: 0 inputs_loc.size: torch.Size([2708, 1433])
0: Starting training... rank 0 run 0
0: Epoch: 001
0: Epoch: 002
0: Epoch: 003
0: Epoch: 004
0: Epoch: 005
0: Epoch: 006
0: Epoch: 007
0: Epoch: 008
0: Epoch: 009
0: Epoch: 010
0: Epoch: 011
0: Epoch: 012
0: Epoch: 013
0: Epoch: 014
0: Epoch: 015
0: Epoch: 016
0: Epoch: 017
0: Epoch: 018
0: Epoch: 019
0: Epoch: 020
0: Epoch: 021
0: Epoch: 022
0: Epoch: 023
0: Epoch: 024
0: Epoch: 025
0: Epoch: 026
0: Epoch: 027
0: Epoch: 028
0: Epoch: 029
0: Epoch: 030
0: Epoch: 031
0: Epoch: 032
0: Epoch: 033
0: Epoch: 034
0: Epoch: 035
0: Epoch: 036
0: Epoch: 037
0: Epoch: 038
0: Epoch: 039
0: Epoch: 040
0: Epoch: 041
0: Epoch: 042
0: Epoch: 043
0: Epoch: 044
0: Epoch: 045
0: Epoch: 046
0: Epoch: 047
0: Epoch: 048
0: Epoch: 049
0: Epoch: 050
0: Epoch: 051
0: Epoch: 052
0: Epoch: 053
0: Epoch: 054
0: Epoch: 055
0: Epoch: 056
0: Epoch: 057
0: Epoch: 058
0: Epoch: 059
0: Epoch: 060
0: Epoch: 061
0: Epoch: 062
0: Epoch: 063
0: Epoch: 064
0: Epoch: 065
0: Epoch: 066
0: Epoch: 067
0: Epoch: 068
0: Epoch: 069
0: Epoch: 070
0: Epoch: 071
0: Epoch: 072
0: Epoch: 073
0: Epoch: 074
0: Epoch: 075
0: Epoch: 076
0: Epoch: 077
0: Epoch: 078
0: Epoch: 079
0: Epoch: 080
0: Epoch: 081
0: Epoch: 082
0: Epoch: 083
0: Epoch: 084
0: Epoch: 085
0: Epoch: 086
0: Epoch: 087
0: Epoch: 088
0: Epoch: 089
0: Epoch: 090
0: Epoch: 091
0: Epoch: 092
0: Epoch: 093
0: Epoch: 094
0: Epoch: 095
0: Epoch: 096
0: Epoch: 097
0: Epoch: 098
0: Epoch: 099
0: total_times_r0: [0.39566826820373535]
0: rank: 0 median_run: 0
0: rank: 0 total_time: 0.39566826820373535
0: rank: 0 comm_time: 0.0
0: rank: 0 comp_time: 0.0
0: rank: 0 scomp_time: 0.0
0: rank: 0 dcomp_time: 0.0
0: rank: 0 bcast_comm_time: 0.0
0: rank: 0 bcast_words: 398617600
0: rank: 0 reduce_comm_time: 0.0
0: rank: 0 op_comm_time: 0.0
0: rank: 0 barrier_time: 0.0
0: rank: 0 tensor([[ -4.1179,  -2.3142,  -3.5202,  ...,  -3.2252,  -3.2203,  -4.1326],
0:         [ -2.4257,  -2.0478,  -1.7789,  ...,  -1.0869,  -2.7786,  -2.5551],
0:         [ -9.7881,  -4.3947,  -1.5525,  ...,  -0.3035,  -7.6774,  -7.6186],
0:         ...,
0:         [ -2.0319,  -1.8395,  -2.0868,  ...,  -2.0309,  -1.8212,  -1.9876],
0:         [ -3.2709,  -2.0389,  -2.5782,  ...,  -1.7912,  -3.1824,  -2.9336],
0:         [-10.7666,  -6.2031,  -9.2070,  ...,  -8.4925,  -6.5577,  -9.9912]],
0:        device='cuda:0', grad_fn=<GCNFuncBackward>)
0: None
